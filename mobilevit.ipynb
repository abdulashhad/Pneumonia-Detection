{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810},{"sourceId":614360,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":461656,"modelId":477412}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport random\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, callbacks\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n\n# -----------------------------\n# CONFIG\n# -----------------------------\nDATASET_DIR = \"/kaggle/input/chest-xray-pneumonia/chest_xray\"\nIMG_SIZE = 128  # Smaller size for lightweight model\nBATCH_SIZE = 16\nEPOCHS = 10\nSEED = 42\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\n# -----------------------------\n# DATA PREPARATION\n# -----------------------------\ndef collect_image_paths(dataset_root):\n    import glob\n    train_path = os.path.join(dataset_root, \"train\")\n    test_path  = os.path.join(dataset_root, \"test\")\n\n    def make_df(path):\n        normal = glob.glob(os.path.join(path, \"NORMAL\", \"*\"))\n        pneumonia = glob.glob(os.path.join(path, \"PNEUMONIA\", \"*\"))\n        return pd.DataFrame({\n            \"image\": normal + pneumonia,\n            \"class\": [\"Normal\"] * len(normal) + [\"Pneumonia\"] * len(pneumonia)\n        })\n\n    return make_df(train_path), make_df(test_path)\n\ndef build_generator(df, img_size, batch_size, shuffle=True, augment=False):\n    datagen = ImageDataGenerator(\n        rescale=1./255,\n        zoom_range=0.1 if augment else 0.0,\n        width_shift_range=0.1 if augment else 0.0,\n        height_shift_range=0.1 if augment else 0.0,\n        horizontal_flip=augment\n    )\n    return datagen.flow_from_dataframe(\n        df, x_col=\"image\", y_col=\"class\",\n        target_size=(img_size, img_size),\n        class_mode=\"binary\",\n        batch_size=batch_size, shuffle=shuffle\n    )\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:25:43.816627Z","iopub.execute_input":"2025-11-20T09:25:43.816881Z","iopub.status.idle":"2025-11-20T09:26:02.113689Z","shell.execute_reply.started":"2025-11-20T09:25:43.816852Z","shell.execute_reply":"2025-11-20T09:26:02.112776Z"}},"outputs":[{"name":"stderr","text":"2025-11-20 09:25:46.646781: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763630746.860133      39 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763630746.920912      39 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# -----------------------------\n# LOAD DATA\n# -----------------------------\ndf_train_all, df_test = collect_image_paths(DATASET_DIR)\ntrain_df, val_df = train_test_split(df_train_all, test_size=0.2,\n                                    stratify=df_train_all[\"class\"], random_state=SEED)\n\ntrain_gen = build_generator(train_df, IMG_SIZE, BATCH_SIZE, augment=True)\nval_gen   = build_generator(val_df, IMG_SIZE, BATCH_SIZE)\ntest_gen  = build_generator(df_test, IMG_SIZE, 1, shuffle=False)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:26:06.732868Z","iopub.execute_input":"2025-11-20T09:26:06.733171Z","iopub.status.idle":"2025-11-20T09:26:13.476338Z","shell.execute_reply.started":"2025-11-20T09:26:06.733150Z","shell.execute_reply":"2025-11-20T09:26:13.475155Z"}},"outputs":[{"name":"stdout","text":"Found 4172 validated image filenames belonging to 2 classes.\nFound 1044 validated image filenames belonging to 2 classes.\nFound 624 validated image filenames belonging to 2 classes.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# -----------------------------\n# MODEL (MobileViT Hybrid - TFLite Compatible)\n# -----------------------------\n\nclass TFLitePatchExtraction(layers.Layer):\n    def __init__(self, patch_size):\n        super().__init__()\n        self.patch_size = patch_size\n        \n    def call(self, images):\n        batch_size = tf.shape(images)[0]\n        height = tf.shape(images)[1]\n        width = tf.shape(images)[2]\n        channels = tf.shape(images)[3]\n        \n        # Calculate output dimensions\n        out_height = height // self.patch_size\n        out_width = width // self.patch_size\n        \n        # Reshape to extract patches using depth_to_space approach\n        x = tf.reshape(images, [batch_size, out_height, self.patch_size, out_width, self.patch_size, channels])\n        x = tf.transpose(x, [0, 1, 3, 2, 4, 5])\n        patches = tf.reshape(x, [batch_size, out_height * out_width, self.patch_size * self.patch_size * channels])\n        \n        return patches\n\nclass PositionEmbedding(layers.Layer):\n    def __init__(self, num_patches, embed_dim):\n        super().__init__()\n        self.num_patches = num_patches\n        self.embed_dim = embed_dim\n        self.position_embedding = layers.Embedding(input_dim=num_patches, output_dim=embed_dim)\n\n    def call(self, inputs):\n        batch_size = tf.shape(inputs)[0]\n        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n        \n        # Get position embeddings and expand to batch size\n        pos_emb = self.position_embedding(positions)\n        pos_emb = tf.expand_dims(pos_emb, axis=0)\n        pos_emb = tf.tile(pos_emb, [batch_size, 1, 1])\n        \n        return inputs + pos_emb\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"num_patches\": self.num_patches,\n            \"embed_dim\": self.embed_dim\n        })\n        return config\n\ndef create_tflite_compatible_vit(img_size=128):\n    \"\"\"Create TFLite-compatible MobileViT hybrid\"\"\"\n    \n    inputs = keras.Input(shape=(img_size, img_size, 3))\n    \n    # CNN backbone for feature extraction\n    x = layers.Conv2D(16, 3, strides=2, padding='same')(inputs)  # 64x64\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    \n    x = layers.Conv2D(32, 3, strides=2, padding='same')(x)  # 32x32\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    \n    x = layers.Conv2D(64, 3, strides=2, padding='same')(x)  # 16x16\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    \n    # Extract patches using TFLite-compatible method\n    patch_size = 4\n    patches = TFLitePatchExtraction(patch_size=patch_size)(x)\n    \n    # Calculate number of patches\n    num_patches = (16 // patch_size) ** 2  # 16x16 feature map divided by patch_size\n    \n    # Project patches and add position embedding\n    projection = layers.Dense(48)(patches)\n    encoded = PositionEmbedding(num_patches=num_patches, embed_dim=48)(projection)\n    \n    # Single transformer layer\n    attn_output = layers.MultiHeadAttention(num_heads=2, key_dim=24)(encoded, encoded)\n    transformed = layers.LayerNormalization(epsilon=1e-6)(attn_output + encoded)\n    \n    # FFN\n    ffn = layers.Dense(96, activation='relu')(transformed)\n    ffn = layers.Dropout(0.1)(ffn)\n    ffn = layers.Dense(48)(ffn)\n    transformed = layers.LayerNormalization(epsilon=1e-6)(ffn + transformed)\n    \n    # Global pooling and classification\n    x = layers.GlobalAveragePooling1D()(transformed)\n    x = layers.Dropout(0.3)(x)\n    outputs = layers.Dense(1, activation='sigmoid')(x)\n    \n    model = keras.Model(inputs=inputs, outputs=outputs)\n    return model\n\n# Create the TFLite-compatible model\nmodel = create_tflite_compatible_vit(img_size=IMG_SIZE)\nmodel.compile(optimizer=keras.optimizers.Adam(1e-4),\n              loss='binary_crossentropy',\n              metrics=['binary_accuracy'])\nmodel.summary()\n\nprint(f\"✅ TFLite-compatible MobileViT created with {model.count_params():,} parameters\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:26:17.715512Z","iopub.execute_input":"2025-11-20T09:26:17.715901Z","iopub.status.idle":"2025-11-20T09:26:18.071549Z","shell.execute_reply.started":"2025-11-20T09:26:17.715871Z","shell.execute_reply":"2025-11-20T09:26:18.070282Z"}},"outputs":[{"name":"stderr","text":"2025-11-20 09:26:17.737778: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │        \u001b[38;5;34m448\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │         \u001b[38;5;34m64\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │      \u001b[38;5;34m4,640\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ tf_lite_patch_extr… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mTFLitePatchExtrac…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m48\u001b[0m)    │     \u001b[38;5;34m49,200\u001b[0m │ tf_lite_patch_ex… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ position_embedding  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m48\u001b[0m)    │        \u001b[38;5;34m768\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mPositionEmbedding\u001b[0m) │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m48\u001b[0m)    │      \u001b[38;5;34m9,408\u001b[0m │ position_embeddi… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ position_embeddi… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m48\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n│                     │                   │            │ position_embeddi… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m48\u001b[0m)    │         \u001b[38;5;34m96\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m96\u001b[0m)    │      \u001b[38;5;34m4,704\u001b[0m │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m96\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m48\u001b[0m)    │      \u001b[38;5;34m4,656\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m48\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n│                     │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m48\u001b[0m)    │         \u001b[38;5;34m96\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m49\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ tf_lite_patch_extr… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TFLitePatchExtrac…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,200</span> │ tf_lite_patch_ex… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ position_embedding  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionEmbedding</span>) │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,408</span> │ position_embeddi… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ position_embeddi… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n│                     │                   │            │ position_embeddi… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,704</span> │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,656</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│                     │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m93,009\u001b[0m (363.32 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,009</span> (363.32 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m92,785\u001b[0m (362.44 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">92,785</span> (362.44 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"✅ TFLite-compatible MobileViT created with 93,009 parameters\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# -----------------------------\n# TRAINING\n# -----------------------------\nes = callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\nrlrop = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=2)\n\nhistory = model.fit(train_gen,\n                    validation_data=val_gen,\n                    epochs=EPOCHS,\n                    callbacks=[es, rlrop],\n                    verbose=1)\n\nmodel.save(\"pneumonia_mobilevit_hybrid.h5\")\nprint(\"✅ Model saved as pneumonia_mobilevit_hybrid.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:54:46.746090Z","iopub.execute_input":"2025-10-13T16:54:46.746352Z","iopub.status.idle":"2025-10-13T17:06:21.832562Z","shell.execute_reply.started":"2025-10-13T16:54:46.746336Z","shell.execute_reply":"2025-10-13T17:06:21.831281Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 264ms/step - binary_accuracy: 0.7745 - loss: 0.4868 - val_binary_accuracy: 0.7433 - val_loss: 1.1979 - learning_rate: 1.0000e-04\nEpoch 2/10\n\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 258ms/step - binary_accuracy: 0.8519 - loss: 0.3270 - val_binary_accuracy: 0.7462 - val_loss: 0.6004 - learning_rate: 1.0000e-04\nEpoch 3/10\n\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 262ms/step - binary_accuracy: 0.8656 - loss: 0.2990 - val_binary_accuracy: 0.8592 - val_loss: 0.3565 - learning_rate: 1.0000e-04\nEpoch 4/10\n\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 260ms/step - binary_accuracy: 0.8920 - loss: 0.2487 - val_binary_accuracy: 0.9186 - val_loss: 0.2096 - learning_rate: 1.0000e-04\nEpoch 5/10\n\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 265ms/step - binary_accuracy: 0.9044 - loss: 0.2268 - val_binary_accuracy: 0.9234 - val_loss: 0.1871 - learning_rate: 1.0000e-04\nEpoch 6/10\n\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 266ms/step - binary_accuracy: 0.9043 - loss: 0.2372 - val_binary_accuracy: 0.8640 - val_loss: 0.3508 - learning_rate: 1.0000e-04\nEpoch 7/10\n\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 262ms/step - binary_accuracy: 0.9198 - loss: 0.2113 - val_binary_accuracy: 0.8180 - val_loss: 0.4594 - learning_rate: 1.0000e-04\nEpoch 8/10\n\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 262ms/step - binary_accuracy: 0.9256 - loss: 0.1965 - val_binary_accuracy: 0.8946 - val_loss: 0.2400 - learning_rate: 2.0000e-05\nEpoch 9/10\n\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 258ms/step - binary_accuracy: 0.9183 - loss: 0.1948 - val_binary_accuracy: 0.8822 - val_loss: 0.2782 - learning_rate: 2.0000e-05\nEpoch 10/10\n\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 267ms/step - binary_accuracy: 0.9256 - loss: 0.1874 - val_binary_accuracy: 0.8946 - val_loss: 0.2455 - learning_rate: 4.0000e-06\n✅ Model saved as pneumonia_mobilevit_hybrid.h5\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# -----------------------------\n# TRAINING\n# -----------------------------\nes = callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\nrlrop = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=2)\n\nhistory = model.fit(train_gen,\n                    validation_data=val_gen,\n                    epochs=EPOCHS,\n                    callbacks=[es, rlrop],\n                    verbose=1)\n\nmodel.save(\"pneumonia_mobilevit_hybrid.h5\")\nprint(\"✅ Model saved as pneumonia_mobilevit_hybrid.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:27:04.562259Z","iopub.execute_input":"2025-11-20T09:27:04.562617Z","iopub.status.idle":"2025-11-20T09:38:44.798568Z","shell.execute_reply.started":"2025-11-20T09:27:04.562593Z","shell.execute_reply":"2025-11-20T09:38:44.797499Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 421ms/step - binary_accuracy: 0.7470 - loss: 0.4985 - val_binary_accuracy: 0.7433 - val_loss: 1.5410 - learning_rate: 1.0000e-04\nEpoch 2/10\n\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 269ms/step - binary_accuracy: 0.8713 - loss: 0.3015 - val_binary_accuracy: 0.8429 - val_loss: 0.3451 - learning_rate: 1.0000e-04\nEpoch 3/10\n\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 278ms/step - binary_accuracy: 0.8898 - loss: 0.2646 - val_binary_accuracy: 0.4109 - val_loss: 1.5877 - learning_rate: 1.0000e-04\nEpoch 4/10\n\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 281ms/step - binary_accuracy: 0.8981 - loss: 0.2438 - val_binary_accuracy: 0.9291 - val_loss: 0.1887 - learning_rate: 1.0000e-04\nEpoch 5/10\n\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 279ms/step - binary_accuracy: 0.9076 - loss: 0.2141 - val_binary_accuracy: 0.7232 - val_loss: 0.6697 - learning_rate: 1.0000e-04\nEpoch 6/10\n\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 278ms/step - binary_accuracy: 0.9181 - loss: 0.1820 - val_binary_accuracy: 0.3822 - val_loss: 1.7229 - learning_rate: 1.0000e-04\nEpoch 7/10\n\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 278ms/step - binary_accuracy: 0.9300 - loss: 0.1776 - val_binary_accuracy: 0.8467 - val_loss: 0.3989 - learning_rate: 2.0000e-05\nEpoch 8/10\n\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 278ms/step - binary_accuracy: 0.9292 - loss: 0.1859 - val_binary_accuracy: 0.9004 - val_loss: 0.2286 - learning_rate: 2.0000e-05\nEpoch 9/10\n\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 278ms/step - binary_accuracy: 0.9251 - loss: 0.1811 - val_binary_accuracy: 0.8621 - val_loss: 0.3508 - learning_rate: 4.0000e-06\n✅ Model saved as pneumonia_mobilevit_hybrid.h5\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# import numpy as np\n\n# # Smooth curves (optional)\n# def smooth_curve(points, factor=0.8):\n#     smoothed = []\n#     last = points[0]\n#     for p in points:\n#         smoothed_val = last * factor + p * (1 - factor)\n#         smoothed.append(smoothed_val)\n#         last = smoothed_val\n#     return smoothed\n\n# # Accuracy Curve\n# plt.figure(figsize=(9,6))\n# plt.plot(smooth_curve(history.history['binary_accuracy']))\n# plt.plot(smooth_curve(history.history['val_binary_accuracy']))\n# plt.xlabel(\"Epochs\")\n# plt.ylabel(\"Accuracy\")\n# plt.legend([\"Train Accuracy\", \"Validation Accuracy\"])\n# plt.title(\"Training vs Validation Accuracy\")\n# plt.grid(True)\n# plt.show()\n\n# # Loss Curve\n# plt.figure(figsize=(9,6))\n# plt.plot(smooth_curve(history.history['loss']))\n# plt.plot(smooth_curve(history.history['val_loss']))\n# plt.xlabel(\"Epochs\")\n# plt.ylabel(\"Loss\")\n# plt.legend([\"Train Loss\", \"Validation Loss\"])\n# plt.title(\"Training vs Validation Loss\")\n# plt.grid(True)\n# plt.show()\nimport keras\nfrom matplotlib import pyplot as plt\n\n# Assuming 'history' is the history object returned from model.fit\n\nplt.plot(history.history['binary_accuracy'])\nplt.plot(history.history['val_binary_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T10:17:28.019370Z","iopub.execute_input":"2025-11-20T10:17:28.020162Z","iopub.status.idle":"2025-11-20T10:17:28.413964Z","shell.execute_reply.started":"2025-11-20T10:17:28.020136Z","shell.execute_reply":"2025-11-20T10:17:28.412834Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_39/965796222.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Get predictions from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Convert the predicted probabilities to class labels (assuming binary classification)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"],"ename":"NameError","evalue":"name 'x_test' is not defined","output_type":"error"}],"execution_count":16},{"cell_type":"code","source":"\n# -----------------------------\n# EVALUATION\n# -----------------------------\npreds = model.predict(test_gen, verbose=1)\npred_labels = (preds > 0.5).astype(int).reshape(-1)\ny_true = df_test[\"class\"].map({\"Normal\":0, \"Pneumonia\":1}).values\n\nprint(\"Test Accuracy:\", accuracy_score(y_true, pred_labels))\nprint(classification_report(y_true, pred_labels, target_names=[\"Normal\",\"Pneumonia\"]))\nprint(\"ROC-AUC:\", roc_auc_score(y_true, preds))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T17:16:32.122523Z","iopub.execute_input":"2025-10-13T17:16:32.123861Z","iopub.status.idle":"2025-10-13T17:16:39.229793Z","shell.execute_reply.started":"2025-10-13T17:16:32.123828Z","shell.execute_reply":"2025-10-13T17:16:39.228606Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m624/624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step\nTest Accuracy: 0.8141025641025641\n              precision    recall  f1-score   support\n\n      Normal       0.95      0.53      0.68       234\n   Pneumonia       0.78      0.98      0.87       390\n\n    accuracy                           0.81       624\n   macro avg       0.86      0.76      0.78       624\nweighted avg       0.84      0.81      0.80       624\n\nROC-AUC: 0.9216852947622179\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# -----------------------------\n# TFLITE INT8 QUANTIZATION\n# -----------------------------\nTFLITE_MODEL_PATH = \"pneumonia_mobilevit_hybrid_int8.tflite\"\nN_REPRESENTATIVE = 100\n\ndef representative_dataset_gen_from_folder(img_folder, img_size, n=N_REPRESENTATIVE):\n    input_name = model.inputs[0].name\n    images = [os.path.join(img_folder, f) for f in os.listdir(img_folder) \n              if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]\n    images = random.sample(images, min(n, len(images)))\n    \n    for img_path in images:\n        img = cv2.imread(img_path)\n        if img is None:\n            continue\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (img_size, img_size))\n        img = np.expand_dims(img, axis=0).astype(np.uint8)  # INT8 input\n        yield {input_name: img}\n\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\nconverter.representative_dataset = lambda: representative_dataset_gen_from_folder(DATASET_DIR, IMG_SIZE)\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\nconverter.inference_input_type = tf.uint8\nconverter.inference_output_type = tf.uint8\n\ntflite_model = converter.convert()\n\nwith open(TFLITE_MODEL_PATH, \"wb\") as f:\n    f.write(tflite_model)\n\nprint(f\"✅ Fully INT8 quantized MobileViT Hybrid model saved as {TFLITE_MODEL_PATH}\")\n\n# Print model size information\noriginal_size = os.path.getsize(\"pneumonia_mobilevit_hybrid.h5\") / (1024 * 1024)\nquantized_size = os.path.getsize(TFLITE_MODEL_PATH) / (1024 * 1024)\n\nprint(f\"\\n📊 Model Size Comparison:\")\nprint(f\"   Original H5: {original_size:.2f} MB\")\nprint(f\"   Quantized TFLite: {quantized_size:.2f} MB\")\nprint(f\"   Compression: {original_size/quantized_size:.1f}x smaller\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T17:16:50.668073Z","iopub.execute_input":"2025-10-13T17:16:50.668407Z","iopub.status.idle":"2025-10-13T17:16:55.351976Z","shell.execute_reply.started":"2025-10-13T17:16:50.668378Z","shell.execute_reply":"2025-10-13T17:16:55.350753Z"}},"outputs":[{"name":"stdout","text":"Saved artifact at '/tmp/tmp_heam6wv'. The following endpoints are available:\n\n* Endpoint 'serve'\n  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='keras_tensor_72')\nOutput Type:\n  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\nCaptures:\n  138793364536208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793364528720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793364527760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793364527952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793364526992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793364528144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059516880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059518416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059518608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059517840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059517072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059518224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059520144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059520720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059520912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059519760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059517456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059520528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059522448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059523024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059522064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059517648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059524176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059522832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059524944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059523984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059525712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059525136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059526480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059522256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059526288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059527440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059528016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059526672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059529168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059527824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059528976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059528400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138793059531088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py:997: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"✅ Fully INT8 quantized MobileViT Hybrid model saved as pneumonia_mobilevit_hybrid_int8.tflite\n\n📊 Model Size Comparison:\n   Original H5: 1.18 MB\n   Quantized TFLite: 0.37 MB\n   Compression: 3.2x smaller\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1760375814.821026      37 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1760375814.821080      37 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\nfully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import tensorflow as tf\nimport keras_cv  # if using MobileViT\n\n# Load model (all custom layers available in this environment)\nmodel_path = \"/kaggle/input/pneumonia_mobilevit_hybrid/pneumonia_mobilevit_hybrid.h5\"\nmodel = tf.keras.models.load_model(model_path, compile=False)\n\n# Convert to TFLite\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\ntflite_model = converter.convert()\n\n# Save TFLite file\ntflite_path = \"/kaggle/working/pneumonia_mobilevit_pi.tflite\"\nwith open(tflite_path, \"wb\") as f:\n    f.write(tflite_model)\n\n# Confirm\nprint(f\"✅ Conversion finished! TFLite file saved to: {tflite_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T14:04:03.786336Z","iopub.execute_input":"2025-10-20T14:04:03.786599Z","iopub.status.idle":"2025-10-20T14:04:03.834688Z","shell.execute_reply.started":"2025-10-20T14:04:03.786581Z","shell.execute_reply":"2025-10-20T14:04:03.833945Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_51/3043895926.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load model (all custom layers available in this environment)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/kaggle/input/pneumonia_mobilevit_hybrid/pneumonia_mobilevit_hybrid.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Convert to TFLite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 564\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/kaggle/input/pneumonia_mobilevit_hybrid/pneumonia_mobilevit_hybrid.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"],"ename":"FileNotFoundError","evalue":"[Errno 2] Unable to synchronously open file (unable to open file: name = '/kaggle/input/pneumonia_mobilevit_hybrid/pneumonia_mobilevit_hybrid.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)","output_type":"error"}],"execution_count":3}]}
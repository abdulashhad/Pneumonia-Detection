{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810},{"sourceId":13443354,"sourceType":"datasetVersion","datasetId":8533058}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport random\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, callbacks\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n\n# -----------------------------\n# CONFIG\n# -----------------------------\nDATASET_DIR = \"/kaggle/input/chest-xray-pneumonia/chest_xray\"\nIMG_SIZE = 128  # Reduced size for Raspberry Pi compatibility\nBATCH_SIZE = 16\nEPOCHS = 15\nSEED = 42\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\n# -----------------------------\n# DATA PREPARATION\n# -----------------------------\ndef collect_image_paths(dataset_root):\n    import glob\n    train_path = os.path.join(dataset_root, \"train\")\n    test_path  = os.path.join(dataset_root, \"test\")\n\n    def make_df(path):\n        normal = glob.glob(os.path.join(path, \"NORMAL\", \"*\"))\n        pneumonia = glob.glob(os.path.join(path, \"PNEUMONIA\", \"*\"))\n        return pd.DataFrame({\n            \"image\": normal + pneumonia,\n            \"class\": [\"Normal\"] * len(normal) + [\"Pneumonia\"] * len(pneumonia)\n        })\n\n    return make_df(train_path), make_df(test_path)\n\ndef build_generator(df, img_size, batch_size, shuffle=True, augment=False):\n    datagen = ImageDataGenerator(\n        rescale=1./255,\n        zoom_range=0.2 if augment else 0.0,\n        width_shift_range=0.15 if augment else 0.0,\n        height_shift_range=0.15 if augment else 0.0,\n        horizontal_flip=augment,\n        rotation_range=10 if augment else 0.0,\n        brightness_range=[0.8, 1.2] if augment else None\n    )\n    return datagen.flow_from_dataframe(\n        df, x_col=\"image\", y_col=\"class\",\n        target_size=(img_size, img_size),\n        class_mode=\"binary\",\n        batch_size=batch_size, shuffle=shuffle\n    )\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:22:25.970539Z","iopub.execute_input":"2025-11-20T09:22:25.970883Z","iopub.status.idle":"2025-11-20T09:22:48.236247Z","shell.execute_reply.started":"2025-11-20T09:22:25.970854Z","shell.execute_reply":"2025-11-20T09:22:48.235062Z"}},"outputs":[{"name":"stderr","text":"2025-11-20 09:22:31.005602: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763630551.326516      39 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763630551.410799      39 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -----------------------------\n# LOAD DATA\n# -----------------------------\ndf_train_all, df_test = collect_image_paths(DATASET_DIR)\ntrain_df, val_df = train_test_split(df_train_all, test_size=0.2,\n                                    stratify=df_train_all[\"class\"], random_state=SEED)\n\ntrain_gen = build_generator(train_df, IMG_SIZE, BATCH_SIZE, augment=True)\nval_gen   = build_generator(val_df, IMG_SIZE, BATCH_SIZE)\ntest_gen  = build_generator(df_test, IMG_SIZE, 1, shuffle=False)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:22:55.451837Z","iopub.execute_input":"2025-11-20T09:22:55.452227Z","iopub.status.idle":"2025-11-20T09:23:05.052204Z","shell.execute_reply.started":"2025-11-20T09:22:55.452198Z","shell.execute_reply":"2025-11-20T09:23:05.050889Z"}},"outputs":[{"name":"stdout","text":"Found 4172 validated image filenames belonging to 2 classes.\nFound 1044 validated image filenames belonging to 2 classes.\nFound 624 validated image filenames belonging to 2 classes.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# -----------------------------\n# MODEL (Optimized VGG16 for Raspberry Pi)\n# -----------------------------\n\ndef create_lightweight_vgg16(img_size=128):\n    \"\"\"Create optimized VGG16-based model for Raspberry Pi with high accuracy\"\"\"\n    \n    # Load pre-trained VGG16 with smaller input size\n    base_model = VGG16(\n        weights='imagenet',\n        include_top=False,\n        input_shape=(img_size, img_size, 3)\n    )\n    \n    # Freeze early layers, fine-tune later layers\n    for layer in base_model.layers[:10]:  # Freeze first 10 layers\n        layer.trainable = False\n    for layer in base_model.layers[10:]:  # Fine-tune later layers\n        layer.trainable = True\n    \n    # Custom classifier head optimized for medical images\n    inputs = keras.Input(shape=(img_size, img_size, 3))\n    x = base_model(inputs, training=False)\n    \n    # Global Average Pooling instead of Flatten to reduce parameters\n    x = layers.GlobalAveragePooling2D()(x)\n    \n    # Attention mechanism for better feature selection\n    attention = layers.Dense(x.shape[-1], activation='sigmoid')(x)\n    x = layers.Multiply()([x, attention])\n    \n    # Enhanced classifier with batch normalization and careful regularization\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.5)(x)\n    \n    x = layers.Dense(128, activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.4)(x)\n    \n    x = layers.Dense(64, activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.3)(x)\n    \n    # Output layer\n    outputs = layers.Dense(1, activation='sigmoid')(x)\n    \n    model = keras.Model(inputs, outputs)\n    return model\n\n# Create the optimized VGG16 model\nmodel = create_lightweight_vgg16(img_size=IMG_SIZE)\n\n# Use lower learning rate for fine-tuning\noptimizer = keras.optimizers.Adam(learning_rate=1e-5)\nmodel.compile(\n    optimizer=optimizer,\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy', keras.metrics.AUC(name='auc')]\n)\n\nmodel.summary()\n\nprint(f\"âœ… Optimized VGG16 created with {model.count_params():,} parameters\")\nprint(\"ğŸš€ Optimized for Raspberry Pi 3 with high accuracy!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:23:15.644915Z","iopub.execute_input":"2025-11-20T09:23:15.645290Z","iopub.status.idle":"2025-11-20T09:23:16.767967Z","shell.execute_reply.started":"2025-11-20T09:23:15.645263Z","shell.execute_reply":"2025-11-20T09:23:16.767090Z"}},"outputs":[{"name":"stderr","text":"2025-11-20 09:23:15.659700: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ input_layer_1       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\nâ”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ \u001b[38;5;34m3\u001b[0m)                â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚ \u001b[38;5;34m14,714,688\u001b[0m â”‚ input_layer_1[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ vgg16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚    \u001b[38;5;34m262,656\u001b[0m â”‚ global_average_pâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ multiply (\u001b[38;5;33mMultiply\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ global_average_pâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚    \u001b[38;5;34m131,328\u001b[0m â”‚ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalization â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚     \u001b[38;5;34m32,896\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m512\u001b[0m â”‚ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m8,256\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m65\u001b[0m â”‚ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ input_layer_1       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> â”‚ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ vgg16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> â”‚ global_average_pâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ global_average_pâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> â”‚ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalization â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,151,681\u001b[0m (57.80 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,151,681</span> (57.80 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,415,297\u001b[0m (51.18 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,415,297</span> (51.18 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,736,384\u001b[0m (6.62 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,736,384</span> (6.62 MB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"âœ… Optimized VGG16 created with 15,151,681 parameters\nğŸš€ Optimized for Raspberry Pi 3 with high accuracy!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\n# -----------------------------\n# TRAINING WITH ENHANCED CALLBACKS\n# -----------------------------\n# Enhanced callbacks for better training\nes = callbacks.EarlyStopping(\n    monitor=\"val_auc\", \n    patience=8, \n    restore_best_weights=True,\n    mode='max',\n    verbose=1\n)\n\nrlrop = callbacks.ReduceLROnPlateau(\n    monitor=\"val_auc\",\n    factor=0.5,\n    patience=4,\n    min_lr=1e-7,\n    mode='max',\n    verbose=1\n)\n\ncheckpoint = callbacks.ModelCheckpoint(\n    \"best_vgg16_pneumonia.h5\",\n    monitor=\"val_auc\",\n    save_best_only=True,\n    mode='max',\n    verbose=1\n)\n\n# Class weights for imbalanced data (usually more pneumonia cases)\nfrom sklearn.utils.class_weight import compute_class_weight\nclass_weights = compute_class_weight(\n    'balanced',\n    classes=np.unique(train_gen.classes),\n    y=train_gen.classes\n)\nclass_weight_dict = {0: class_weights[0], 1: class_weights[1]}\nprint(f\"ğŸ“Š Class weights: {class_weight_dict}\")\n\nprint(\"ğŸ¯ Starting training with optimized VGG16...\")\nhistory = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=EPOCHS,\n    callbacks=[es, rlrop, checkpoint],\n    class_weight=class_weight_dict,\n    verbose=1\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T17:29:29.509080Z","iopub.execute_input":"2025-10-13T17:29:29.509379Z","iopub.status.idle":"2025-10-13T20:27:43.561517Z","shell.execute_reply.started":"2025-10-13T17:29:29.509358Z","shell.execute_reply":"2025-10-13T20:27:43.558676Z"}},"outputs":[{"name":"stdout","text":"ğŸ“Š Class weights: {0: 1.9440820130475303, 1: 0.6731203614069055}\nğŸ¯ Starting training with optimized VGG16...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - auc: 0.7109 - binary_accuracy: 0.6261 - loss: 0.6841\nEpoch 1: val_auc improved from -inf to 0.97029, saving model to best_vgg16_pneumonia.h5\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m766s\u001b[0m 3s/step - auc: 0.7112 - binary_accuracy: 0.6264 - loss: 0.6836 - val_auc: 0.9703 - val_binary_accuracy: 0.3649 - val_loss: 0.7336 - learning_rate: 1.0000e-05\nEpoch 2/15\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - auc: 0.9062 - binary_accuracy: 0.7673 - loss: 0.4274\nEpoch 2: val_auc improved from 0.97029 to 0.98289, saving model to best_vgg16_pneumonia.h5\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m752s\u001b[0m 3s/step - auc: 0.9063 - binary_accuracy: 0.7673 - loss: 0.4273 - val_auc: 0.9829 - val_binary_accuracy: 0.6370 - val_loss: 0.7959 - learning_rate: 1.0000e-05\nEpoch 3/15\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - auc: 0.9415 - binary_accuracy: 0.8039 - loss: 0.3639\nEpoch 3: val_auc improved from 0.98289 to 0.98926, saving model to best_vgg16_pneumonia.h5\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m803s\u001b[0m 3s/step - auc: 0.9415 - binary_accuracy: 0.8039 - loss: 0.3638 - val_auc: 0.9893 - val_binary_accuracy: 0.8573 - val_loss: 0.4159 - learning_rate: 1.0000e-05\nEpoch 4/15\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - auc: 0.9564 - binary_accuracy: 0.8351 - loss: 0.3165\nEpoch 4: val_auc did not improve from 0.98926\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m747s\u001b[0m 3s/step - auc: 0.9564 - binary_accuracy: 0.8352 - loss: 0.3165 - val_auc: 0.9869 - val_binary_accuracy: 0.5958 - val_loss: 0.8197 - learning_rate: 1.0000e-05\nEpoch 5/15\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - auc: 0.9602 - binary_accuracy: 0.8535 - loss: 0.2967\nEpoch 5: val_auc did not improve from 0.98926\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m860s\u001b[0m 3s/step - auc: 0.9603 - binary_accuracy: 0.8535 - loss: 0.2967 - val_auc: 0.9716 - val_binary_accuracy: 0.8123 - val_loss: 0.7178 - learning_rate: 1.0000e-05\nEpoch 6/15\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - auc: 0.9616 - binary_accuracy: 0.8563 - loss: 0.2822\nEpoch 6: val_auc improved from 0.98926 to 0.99436, saving model to best_vgg16_pneumonia.h5\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m738s\u001b[0m 3s/step - auc: 0.9616 - binary_accuracy: 0.8563 - loss: 0.2822 - val_auc: 0.9944 - val_binary_accuracy: 0.9387 - val_loss: 0.2274 - learning_rate: 1.0000e-05\nEpoch 7/15\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - auc: 0.9626 - binary_accuracy: 0.8647 - loss: 0.2853\nEpoch 7: val_auc did not improve from 0.99436\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m735s\u001b[0m 3s/step - auc: 0.9626 - binary_accuracy: 0.8647 - loss: 0.2854 - val_auc: 0.9807 - val_binary_accuracy: 0.7452 - val_loss: 0.7645 - learning_rate: 1.0000e-05\nEpoch 8/15\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - auc: 0.9717 - binary_accuracy: 0.8830 - loss: 0.2513\nEpoch 8: val_auc did not improve from 0.99436\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m736s\u001b[0m 3s/step - auc: 0.9717 - binary_accuracy: 0.8830 - loss: 0.2513 - val_auc: 0.9926 - val_binary_accuracy: 0.9148 - val_loss: 0.3005 - learning_rate: 1.0000e-05\nEpoch 9/15\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - auc: 0.9754 - binary_accuracy: 0.8975 - loss: 0.2366\nEpoch 9: val_auc did not improve from 0.99436\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m739s\u001b[0m 3s/step - auc: 0.9754 - binary_accuracy: 0.8975 - loss: 0.2366 - val_auc: 0.9842 - val_binary_accuracy: 0.8582 - val_loss: 0.5191 - learning_rate: 1.0000e-05\nEpoch 10/15\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - auc: 0.9697 - binary_accuracy: 0.8863 - loss: 0.2540\nEpoch 10: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n\nEpoch 10: val_auc did not improve from 0.99436\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m737s\u001b[0m 3s/step - auc: 0.9697 - binary_accuracy: 0.8863 - loss: 0.2539 - val_auc: 0.9787 - val_binary_accuracy: 0.8381 - val_loss: 0.6065 - learning_rate: 1.0000e-05\nEpoch 11/15\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - auc: 0.9754 - binary_accuracy: 0.9003 - loss: 0.2295\nEpoch 11: val_auc did not improve from 0.99436\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m796s\u001b[0m 3s/step - auc: 0.9754 - binary_accuracy: 0.9003 - loss: 0.2295 - val_auc: 0.9937 - val_binary_accuracy: 0.9119 - val_loss: 0.3159 - learning_rate: 5.0000e-06\nEpoch 12/15\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - auc: 0.9794 - binary_accuracy: 0.8984 - loss: 0.2252\nEpoch 12: val_auc did not improve from 0.99436\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m736s\u001b[0m 3s/step - auc: 0.9794 - binary_accuracy: 0.8984 - loss: 0.2252 - val_auc: 0.9650 - val_binary_accuracy: 0.7002 - val_loss: 0.9862 - learning_rate: 5.0000e-06\nEpoch 13/15\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - auc: 0.9802 - binary_accuracy: 0.9041 - loss: 0.2122\nEpoch 13: val_auc did not improve from 0.99436\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m744s\u001b[0m 3s/step - auc: 0.9802 - binary_accuracy: 0.9041 - loss: 0.2122 - val_auc: 0.9933 - val_binary_accuracy: 0.8640 - val_loss: 0.4558 - learning_rate: 5.0000e-06\nEpoch 14/15\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - auc: 0.9810 - binary_accuracy: 0.9191 - loss: 0.2040\nEpoch 14: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n\nEpoch 14: val_auc did not improve from 0.99436\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m805s\u001b[0m 3s/step - auc: 0.9810 - binary_accuracy: 0.9191 - loss: 0.2041 - val_auc: 0.9923 - val_binary_accuracy: 0.8946 - val_loss: 0.3727 - learning_rate: 5.0000e-06\nEpoch 14: early stopping\nRestoring model weights from the end of the best epoch: 6.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"\n# -----------------------------\n# TRAINING WITH ENHANCED CALLBACKS\n# -----------------------------\n# Enhanced callbacks for better training\nes = callbacks.EarlyStopping(\n    monitor=\"val_auc\", \n    patience=8, \n    restore_best_weights=True,\n    mode='max',\n    verbose=1\n)\n\nrlrop = callbacks.ReduceLROnPlateau(\n    monitor=\"val_auc\",\n    factor=0.5,\n    patience=4,\n    min_lr=1e-7,\n    mode='max',\n    verbose=1\n)\n\ncheckpoint = callbacks.ModelCheckpoint(\n    \"best_vgg16_pneumonia.h5\",\n    monitor=\"val_auc\",\n    save_best_only=True,\n    mode='max',\n    verbose=1\n)\n\n# Class weights for imbalanced data (usually more pneumonia cases)\nfrom sklearn.utils.class_weight import compute_class_weight\nclass_weights = compute_class_weight(\n    'balanced',\n    classes=np.unique(train_gen.classes),\n    y=train_gen.classes\n)\nclass_weight_dict = {0: class_weights[0], 1: class_weights[1]}\nprint(f\"ğŸ“Š Class weights: {class_weight_dict}\")\n\nprint(\"ğŸ¯ Starting training with optimized VGG16...\")\nhistory = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=EPOCHS,\n    callbacks=[es, rlrop, checkpoint],\n    class_weight=class_weight_dict,\n    verbose=1\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:28:31.724263Z","iopub.execute_input":"2025-11-20T09:28:31.724732Z","execution_failed":"2025-11-20T11:20:56.707Z"}},"outputs":[{"name":"stdout","text":"ğŸ“Š Class weights: {0: 1.9440820130475303, 1: 0.6731203614069055}\nğŸ¯ Starting training with optimized VGG16...\nEpoch 1/15\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - auc: 0.7963 - binary_accuracy: 0.6695 - loss: 0.5922","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_auc improved from -inf to 0.96964, saving model to best_vgg16_pneumonia.h5\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m939s\u001b[0m 4s/step - auc: 0.7965 - binary_accuracy: 0.6697 - loss: 0.5919 - val_auc: 0.9696 - val_binary_accuracy: 0.4205 - val_loss: 0.6989 - learning_rate: 1.0000e-05\nEpoch 2/15\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - auc: 0.9204 - binary_accuracy: 0.7872 - loss: 0.4065\nEpoch 2: val_auc improved from 0.96964 to 0.98244, saving model to best_vgg16_pneumonia.h5\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m880s\u001b[0m 3s/step - auc: 0.9205 - binary_accuracy: 0.7873 - loss: 0.4064 - val_auc: 0.9824 - val_binary_accuracy: 0.7998 - val_loss: 0.6002 - learning_rate: 1.0000e-05\nEpoch 3/15\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - auc: 0.9471 - binary_accuracy: 0.8321 - loss: 0.3397\nEpoch 3: val_auc improved from 0.98244 to 0.98381, saving model to best_vgg16_pneumonia.h5\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m882s\u001b[0m 3s/step - auc: 0.9471 - binary_accuracy: 0.8321 - loss: 0.3396 - val_auc: 0.9838 - val_binary_accuracy: 0.8276 - val_loss: 0.5418 - learning_rate: 1.0000e-05\nEpoch 4/15\n\u001b[1m157/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5:11\u001b[0m 3s/step - auc: 0.9438 - binary_accuracy: 0.8264 - loss: 0.3443","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Load best model\nmodel = keras.models.load_model(\"best_vgg16_pneumonia.h5\")\nprint(\"âœ… Best model loaded for evaluation\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T20:29:58.312315Z","iopub.execute_input":"2025-10-13T20:29:58.313743Z","iopub.status.idle":"2025-10-13T20:29:58.799168Z","shell.execute_reply.started":"2025-10-13T20:29:58.313673Z","shell.execute_reply":"2025-10-13T20:29:58.798220Z"}},"outputs":[{"name":"stdout","text":"âœ… Best model loaded for evaluation\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# ---- Accuracy Curve ----\nplt.figure(figsize=(6,5))\nplt.plot(history.history['binary_accuracy'])\nplt.plot(history.history['val_binary_accuracy'])\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend([\"Train Accuracy\", \"Validation Accuracy\"])\nplt.title(\"Training vs Validation Accuracy\")\nplt.show()\n\n# ---- Loss Curve ----\nplt.figure(figsize=(6,5))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend([\"Train Loss\", \"Validation Loss\"])\nplt.title(\"Training vs Validation Loss\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:17:28.766794Z","iopub.execute_input":"2025-11-20T09:17:28.767608Z","iopub.status.idle":"2025-11-20T09:17:28.873845Z","shell.execute_reply.started":"2025-11-20T09:17:28.767573Z","shell.execute_reply":"2025-11-20T09:17:28.872308Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_39/1652925757.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ---- Accuracy Curve ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binary_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_binary_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"],"ename":"NameError","evalue":"name 'history' is not defined","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x500 with 0 Axes>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"\n# -----------------------------\n# EVALUATION\n# -----------------------------\nprint(\"ğŸ§ª Evaluating model on test set...\")\npreds = model.predict(test_gen, verbose=1)\npred_labels = (preds > 0.5).astype(int).reshape(-1)\ny_true = df_test[\"class\"].map({\"Normal\":0, \"Pneumonia\":1}).values\n\ntest_accuracy = accuracy_score(y_true, pred_labels)\ntest_auc = roc_auc_score(y_true, preds)\n\nprint(f\"ğŸ¯ Test Accuracy: {test_accuracy:.4f}\")\nprint(f\"ğŸ“Š Test ROC-AUC: {test_auc:.4f}\")\nprint(classification_report(y_true, pred_labels, target_names=[\"Normal\",\"Pneumonia\"]))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T20:30:02.931517Z","iopub.execute_input":"2025-10-13T20:30:02.932270Z","iopub.status.idle":"2025-10-13T20:30:58.160363Z","shell.execute_reply.started":"2025-10-13T20:30:02.932116Z","shell.execute_reply":"2025-10-13T20:30:58.159385Z"}},"outputs":[{"name":"stdout","text":"ğŸ§ª Evaluating model on test set...\n\u001b[1m624/624\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 87ms/step\nğŸ¯ Test Accuracy: 0.9279\nğŸ“Š Test ROC-AUC: 0.9705\n              precision    recall  f1-score   support\n\n      Normal       0.96      0.84      0.90       234\n   Pneumonia       0.91      0.98      0.94       390\n\n    accuracy                           0.93       624\n   macro avg       0.94      0.91      0.92       624\nweighted avg       0.93      0.93      0.93       624\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# -----------------------------\n# TFLITE QUANTIZATION FOR RASPBERRY PI 3\n# -----------------------------\nTFLITE_MODEL_PATH = \"pneumonia_vgg16_quantized.tflite\"\nTFLITE_FLOAT_MODEL_PATH = \"pneumonia_vgg16_float.tflite\"\n\ndef representative_dataset_gen():\n    \"\"\"Representative dataset for quantization\"\"\"\n    for _ in range(100):\n        # Generate random data that matches training distribution\n        data = np.random.uniform(0, 1, (1, IMG_SIZE, IMG_SIZE, 3)).astype(np.float32)\n        yield [data]\n\nprint(\"ğŸ”„ Converting to TFLite for Raspberry Pi 3...\")\n\n# Strategy 1: First create a float32 model (most compatible)\nconverter_float = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_float_model = converter_float.convert()\n\nwith open(TFLITE_FLOAT_MODEL_PATH, \"wb\") as f:\n    f.write(tflite_float_model)\nprint(f\"âœ… Float32 TFLite model saved: {TFLITE_FLOAT_MODEL_PATH}\")\n\n# Strategy 2: Try dynamic range quantization (good balance)\ntry:\n    converter_dynamic = tf.lite.TFLiteConverter.from_keras_model(model)\n    converter_dynamic.optimizations = [tf.lite.Optimize.DEFAULT]\n    tflite_dynamic_model = converter_dynamic.convert()\n    \n    dynamic_path = \"pneumonia_vgg16_dynamic_quant.tflite\"\n    with open(dynamic_path, \"wb\") as f:\n        f.write(tflite_dynamic_model)\n    print(f\"âœ… Dynamic range quantized model saved: {dynamic_path}\")\nexcept Exception as e:\n    print(f\"âš ï¸ Dynamic quantization failed: {e}\")\n\n# Strategy 3: Try full INT8 quantization (smallest size)\ntry:\n    converter_int8 = tf.lite.TFLiteConverter.from_keras_model(model)\n    converter_int8.optimizations = [tf.lite.Optimize.DEFAULT]\n    converter_int8.representative_dataset = representative_dataset_gen\n    \n    # For maximum compatibility, don't force input/output types\n    # converter_int8.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n    # converter_int8.inference_input_type = tf.uint8\n    # converter_int8.inference_output_type = tf.uint8\n    \n    tflite_int8_model = converter_int8.convert()\n    \n    with open(TFLITE_MODEL_PATH, \"wb\") as f:\n        f.write(tflite_int8_model)\n    print(f\"âœ… INT8 quantized model saved: {TFLITE_MODEL_PATH}\")\nexcept Exception as e:\n    print(f\"âš ï¸ INT8 quantization failed: {e}\")\n    # Fallback to dynamic quantization\n    TFLITE_MODEL_PATH = dynamic_path\n\n# Test TFLite model\nprint(\"ğŸ§ª Testing TFLite model...\")\ninterpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL_PATH)\ninterpreter.allocate_tensors()\nprint(\"âœ… TFLite model loaded successfully!\")\n\n# Model size analysis\nprint(\"\\nğŸ“Š MODEL SIZE ANALYSIS FOR RASPBERRY PI 3:\")\noriginal_size = os.path.getsize(\"best_vgg16_pneumonia.h5\") / (1024 * 1024)\ntflite_size = os.path.getsize(TFLITE_MODEL_PATH) / (1024 * 1024)\n\nprint(f\"   Original H5: {original_size:.2f} MB\")\nprint(f\"   TFLite Quantized: {tflite_size:.2f} MB\")\nprint(f\"   Compression: {original_size/tflite_size:.1f}x smaller\")\n\n# Memory requirements estimation\nprint(f\"   Estimated RAM usage: {tflite_size * 2:.1f} MB (2x model size)\")\n\n# Performance tips for Raspberry Pi\nprint(\"\\nğŸ¯ RASPBERRY PI 3 DEPLOYMENT TIPS:\")\nprint(\"   1. Use float32 model for best accuracy\")\nprint(\"   2. Use quantized model for faster inference\")\nprint(\"   3. Expected inference time: 200-500ms per image\")\nprint(\"   4. Recommended: Use with TensorFlow Lite Runtime\")\nprint(\"   5. Enable ARM NEON optimizations for better performance\")\n\n# Save training history for analysis\nhistory_df = pd.DataFrame(history.history)\nhistory_df.to_csv(\"vgg16_training_history.csv\", index=False)\nprint(\"âœ… Training history saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T20:32:03.104249Z","iopub.execute_input":"2025-10-13T20:32:03.104615Z","iopub.status.idle":"2025-10-13T20:32:50.577143Z","shell.execute_reply.started":"2025-10-13T20:32:03.104584Z","shell.execute_reply":"2025-10-13T20:32:50.576146Z"}},"outputs":[{"name":"stdout","text":"ğŸ”„ Converting to TFLite for Raspberry Pi 3...\nSaved artifact at '/tmp/tmp388torbp'. The following endpoints are available:\n\n* Endpoint 'serve'\n  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='input_layer_1')\nOutput Type:\n  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\nCaptures:\n  131940930129360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940930131472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940930130896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940930127440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940930126672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940930131856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920151376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920152336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920151760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920153104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920152528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920153872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920153296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920154640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920154064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920155408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920154832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920156176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920155600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920156944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920156368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920157712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920157136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920158480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920157904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920159248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920160784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920162128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920161552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920162896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920163088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920162320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920161168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920162704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920164624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920165200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920165392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920164240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920161360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920165008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920160016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920165776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940446602256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940446601488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920163856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940446601680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940446603600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940446604176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nW0000 00:00:1760387529.132182      37 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1760387529.132326      37 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\nI0000 00:00:1760387529.160897      37 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n","output_type":"stream"},{"name":"stdout","text":"âœ… Float32 TFLite model saved: pneumonia_vgg16_float.tflite\nSaved artifact at '/tmp/tmptzf9823b'. The following endpoints are available:\n\n* Endpoint 'serve'\n  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='input_layer_1')\nOutput Type:\n  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\nCaptures:\n  131940930129360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940930131472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940930130896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940930127440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940930126672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940930131856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920151376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920152336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920151760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920153104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920152528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920153872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920153296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920154640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920154064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920155408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920154832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920156176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920155600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920156944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920156368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920157712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920157136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920158480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920157904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920159248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920160784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920162128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920161552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920162896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920163088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920162320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920161168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920162704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920164624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920165200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920165392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920164240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920161360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920165008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920160016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920165776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940446602256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940446601488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920163856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940446601680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940446603600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940446604176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1760387537.511725      37 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1760387537.511765      37 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n","output_type":"stream"},{"name":"stdout","text":"âœ… Dynamic range quantized model saved: pneumonia_vgg16_dynamic_quant.tflite\nSaved artifact at '/tmp/tmpy2ufsn01'. The following endpoints are available:\n\n* Endpoint 'serve'\n  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='input_layer_1')\nOutput Type:\n  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\nCaptures:\n  131940930129360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940930131472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940930130896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940930127440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940930126672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940930131856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920151376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920152336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920151760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920153104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920152528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920153872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920153296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920154640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920154064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920155408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920154832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920156176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920155600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920156944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920156368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920157712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920157136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920158480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920157904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920159248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920160784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920162128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920161552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920162896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920163088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920162320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920161168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920162704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920164624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920165200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920165392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920164240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920161360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920165008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920160016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920165776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940446602256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940446601488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131939920163856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940446601680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940446603600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  131940446604176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py:997: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n  warnings.warn(\nW0000 00:00:1760387546.162704      37 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1760387546.162742      37 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\nfully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n","output_type":"stream"},{"name":"stdout","text":"âœ… INT8 quantized model saved: pneumonia_vgg16_quantized.tflite\nğŸ§ª Testing TFLite model...\nâœ… TFLite model loaded successfully!\n\nğŸ“Š MODEL SIZE ANALYSIS FOR RASPBERRY PI 3:\n   Original H5: 160.28 MB\n   TFLite Quantized: 14.59 MB\n   Compression: 11.0x smaller\n   Estimated RAM usage: 29.2 MB (2x model size)\n\nğŸ¯ RASPBERRY PI 3 DEPLOYMENT TIPS:\n   1. Use float32 model for best accuracy\n   2. Use quantized model for faster inference\n   3. Expected inference time: 200-500ms per image\n   4. Recommended: Use with TensorFlow Lite Runtime\n   5. Enable ARM NEON optimizations for better performance\nâœ… Training history saved!\n","output_type":"stream"},{"name":"stderr","text":"INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Load your H5 model (no compile needed)\nmodel = load_model(\"/kaggle/input/majorproject/best_vgg16_pneumonia.h5\", compile=False)\n\n# Save as SavedModel (folder path, no save_format)\nmodel.save(\"best_vgg16_saved_model\")  # This will create a folder\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T12:24:27.388406Z","iopub.execute_input":"2025-10-20T12:24:27.388787Z","iopub.status.idle":"2025-10-20T12:24:28.278964Z","shell.execute_reply.started":"2025-10-20T12:24:27.388760Z","shell.execute_reply":"2025-10-20T12:24:28.277276Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/945956704.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Save as SavedModel (folder path, no save_format)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_vgg16_saved_model\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This will create a folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         )\n\u001b[0;32m--> 114\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;34m\"Invalid filepath extension for saving. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;34m\"Please add either a `.keras` extension for the native Keras \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=best_vgg16_saved_model."],"ename":"ValueError","evalue":"Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=best_vgg16_saved_model.","output_type":"error"}],"execution_count":2}]}